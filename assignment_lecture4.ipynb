{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pankaj-pixel/NLP/blob/main/assignment_lecture4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following dataset - https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ],
      "metadata": {
        "id": "3iKVSl7hDZJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#feature extraction assigment\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string\n",
        "from textblob import TextBlob\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "df = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "review = df['review']\n",
        "reviews = review.str.lower()  # Convert all reviews to lowercase\n",
        "print(\"Step 1: Loaded dataset and converted reviews to lowercase.\")\n",
        "\n",
        "# Step 2: Remove HTML tags\n",
        "def remove_html(series):\n",
        "    html = re.compile('<.*?>')\n",
        "    new_reviews = html.sub('', series)\n",
        "    return new_reviews\n",
        "\n",
        "html_data = reviews.apply(remove_html)\n",
        "print(\"Step 2: Removed HTML tags.\")\n",
        "\n",
        "# Step 3: Remove punctuation\n",
        "def remove_punc(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "punc_remove = html_data.apply(remove_punc)\n",
        "print(\"Step 3: Removed punctuation.\")\n",
        "\n",
        "# Step 4: Spelling correction\n",
        "def spelling_checker(text):\n",
        "    data = TextBlob(text)\n",
        "\n",
        "    correct = data.correct().string\n",
        "    return correct\n",
        "\n",
        "# Apply spelling correction to each review in the DataFrame\n",
        "small_sample = punc_remove.head(10)  # Use only the first 10 reviews\n",
        "corrected_sample = small_sample.apply(spelling_checker)\n",
        "#print(corrected_sample)\n",
        "#corrected_data = punc_remove.apply(spelling_checker)\n",
        "print(\"Step 4: Corrected spelling.\")\n",
        "\n",
        "# Step 5: Remove stopwords\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "final_data = corrected_sample.apply(remove_stopwords)\n",
        "print(\"Step 5: Removed stopwords.\")\n",
        "\n",
        "# Final output\n",
        "print(\"Preprocessing complete. Here is the final processed data:\")\n",
        "print(final_data[1])\n",
        "\n"
      ],
      "metadata": {
        "id": "-MnjNsGhDfCA",
        "outputId": "217ac3eb-67a2-4a7c-b630-9d2b083b9d88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Loaded dataset and converted reviews to lowercase.\n",
            "Step 2: Removed HTML tags.\n",
            "Step 3: Removed punctuation.\n",
            "Step 4: Corrected spelling.\n",
            "Step 5: Removed stopwords.\n",
            "Preprocessing complete. Here is the final processed data:\n",
            "wonderful little production filling technique assuming oldtimebbc fashion gives comforting sometimes discomforting sense realism entire piece actors extremely well chosen michael sheen got polar voices pat truly see fearless editing guided references williams diary entries well worth watching terrific written performed piece wasteful production one great masters comedy life realism really comes home little things fantasy guard rather use traditional dream technique remains solid disappears plays knowledge senses particularly scenes concerning norton halliwell sets particularly flat halliwells morals decorating every surface terribly well done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 2\n",
        "\n",
        "# Find out the number of words in the entire corpus and also the total number of unique words(vocabulary) using just python"
      ],
      "metadata": {
        "id": "VuVSlxaZDqsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 3\n",
        "\n",
        "# Apply One Hot Encoding"
      ],
      "metadata": {
        "id": "B9BcW8aLD4nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 4\n",
        "\n",
        "# Apply bag words and find the vocabulary also find the times each word has occured"
      ],
      "metadata": {
        "id": "tSQ9sf6NFSTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 5\n",
        "\n",
        "# Apply bag of bi-gram and bag of tri-gram and write down your observation about the dimensionality of the vocabulary"
      ],
      "metadata": {
        "id": "vR8LnGwZFbhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 6\n",
        "\n",
        "# Apply tf-idf and find out the idf scores of words, also find out the vocabulary."
      ],
      "metadata": {
        "id": "coyvsD3OFrB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n7abDAiFF2Ij"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}